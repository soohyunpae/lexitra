from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import logging
import os
import openai
from lexitra.tm import find_tm_match
from datetime import datetime
from dotenv import load_dotenv
load_dotenv(dotenv_path=".env.local")

app = FastAPI()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("translate")

class TranslationRequest(BaseModel):
    text: str
    sourceLang: str
    targetLang: str

def calculate_similarity(a: str, b: str) -> float:
    """ì•„ì£¼ ë‹¨ìˆœí•œ ìœ ì‚¬ë„ ê³„ì‚° (ë‹¨ì–´ ì¼ì¹˜ ê¸°ë°˜ ë¹„ìœ¨)"""
    set_a = set(a.lower().split())
    set_b = set(b.lower().split())
    if not set_a or not set_b:
        return 0.0
    return len(set_a & set_b) / len(set_a | set_b)

client = openai.OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

@app.post("/")
async def translate_endpoint(request: TranslationRequest):
    logger.info("ë²ˆì—­ ìš”ì²­ ìˆ˜ì‹ : %s", request)
    tm_result = find_tm_match(request.text, request.sourceLang, request.targetLang)

    # TM ë§¤ì¹˜ê°€ ìˆì„ ê²½ìš°ì—ë§Œ ë°˜í™˜
    if tm_result.get("match") and tm_result.get("target"):
        logger.info("âœ… TMì—ì„œ ê²°ê³¼ ë°œê²¬: %s", tm_result)
        return {"result": tm_result["target"], "fromTM": True}
    
    logger.info("ğŸŒ€ TM ë§¤ì¹˜ ì—†ìŒ. GPTë¥¼ ì‚¬ìš©í•  ì˜ˆì •ì…ë‹ˆë‹¤.")
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": f"You are a professional translator that translates from {request.sourceLang} to {request.targetLang}."},
                {"role": "user", "content": request.text}
            ]
        )
        logger.info("ğŸ§  GPT ì‘ë‹µ ì „ì²´: %s", response)
        gpt_translation = response.choices[0].message.content
        return {"result": gpt_translation.strip(), "fromTM": False}
    except Exception as e:
        logger.error("âŒ GPT ë²ˆì—­ ì‹¤íŒ¨: %s", e)
        raise HTTPException(status_code=500, detail="GPT ë²ˆì—­ ì‹¤íŒ¨")